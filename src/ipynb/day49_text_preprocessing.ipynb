{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I eventually want to do text analysis with the Kickstarter data, but I'll need to do some data cleaning and text preprocessing before I can do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Load data from database. List of columns found on day44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbname = \"kick\"\n",
    "tblname = \"info\"\n",
    "\n",
    "# Connect to database\n",
    "conn = psycopg2.connect(dbname=dbname)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>blurb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1312331512</td>\n",
       "      <td>Otherkin The Animated Series</td>\n",
       "      <td>We have a fully developed 2D animated series t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80827270</td>\n",
       "      <td>Paradigm Spiral - The Animated Series</td>\n",
       "      <td>A sci-fi fantasy 2.5D anime styled series abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>737219121</td>\n",
       "      <td>I'm Sticking With You.</td>\n",
       "      <td>A film created entirely out of paper, visual e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946566454</td>\n",
       "      <td>A Tale of Faith - An Animated Short Film</td>\n",
       "      <td>A Tale of Faith is an animated short film base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>591797827</td>\n",
       "      <td>Honeybee: The Animated Series Trailer</td>\n",
       "      <td>Honeybee is a cartoon about a girl who can tal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                      name  \\\n",
       "0  1312331512              Otherkin The Animated Series   \n",
       "1    80827270     Paradigm Spiral - The Animated Series   \n",
       "2   737219121                    I'm Sticking With You.   \n",
       "3  1946566454  A Tale of Faith - An Animated Short Film   \n",
       "4   591797827     Honeybee: The Animated Series Trailer   \n",
       "\n",
       "                                               blurb  \n",
       "0  We have a fully developed 2D animated series t...  \n",
       "1  A sci-fi fantasy 2.5D anime styled series abou...  \n",
       "2  A film created entirely out of paper, visual e...  \n",
       "3  A Tale of Faith is an animated short film base...  \n",
       "4  Honeybee is a cartoon about a girl who can tal...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = [\"id\", \"name\", \"blurb\"]\n",
    "\n",
    "cur.execute(\"SELECT {col} FROM {tbl}\".format(col=', '.join(colnames), tbl=tblname))\n",
    "rows = cur.fetchall()\n",
    "\n",
    "pd.DataFrame(rows, columns=colnames).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to combine `name` and `blurb`. We can use the `concat_ws` command in postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1312331512</td>\n",
       "      <td>We have a fully developed 2D animated series t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80827270</td>\n",
       "      <td>A sci-fi fantasy 2.5D anime styled series abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>737219121</td>\n",
       "      <td>A film created entirely out of paper, visual e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946566454</td>\n",
       "      <td>A Tale of Faith is an animated short film base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>591797827</td>\n",
       "      <td>Honeybee is a cartoon about a girl who can tal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           document\n",
       "0  1312331512  We have a fully developed 2D animated series t...\n",
       "1    80827270  A sci-fi fantasy 2.5D anime styled series abou...\n",
       "2   737219121  A film created entirely out of paper, visual e...\n",
       "3  1946566454  A Tale of Faith is an animated short film base...\n",
       "4   591797827  Honeybee is a cartoon about a girl who can tal..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treat name + blurb as 1 document\n",
    "cur.execute(\"SELECT id, concat_ws(name, blurb) FROM info\")\n",
    "rows = cur.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"id\", \"document\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# close communication\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177140, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of documents\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing for 1 document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A sci-fi fantasy 2.5D anime styled series about some guys trying to save the world, probably...'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df[\"document\"][1]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a sci-fi fantasy 2.5d anime styled series about some guys trying to save the world, probably...'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of word & tokenization\n",
    "Digits are also removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'scifi',\n",
       " 'fantasy',\n",
       " 'd',\n",
       " 'anime',\n",
       " 'styled',\n",
       " 'series',\n",
       " 'about',\n",
       " 'some',\n",
       " 'guys',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'save',\n",
       " 'the',\n",
       " 'world',\n",
       " 'probably']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.wordpunct_tokenize(re.sub('[^a-zA-Z_ ]', '', text))\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords\n",
    "\n",
    "Reference: https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "print(len(english_stopwords))\n",
    "print(english_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a list of 153 english stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scifi',\n",
       " 'fantasy',\n",
       " 'anime',\n",
       " 'styled',\n",
       " 'series',\n",
       " 'guys',\n",
       " 'trying',\n",
       " 'save',\n",
       " 'world',\n",
       " 'probably']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords from document\n",
    "words = [w for w in words if not w in english_stopwords]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming vs Lemmatization\n",
    "Reference: http://stackoverflow.com/questions/771918/how-do-i-do-word-stemming-or-lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "port = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scifi',\n",
       " 'fantasi',\n",
       " 'anim',\n",
       " 'style',\n",
       " 'seri',\n",
       " 'guy',\n",
       " 'tri',\n",
       " 'save',\n",
       " 'world',\n",
       " 'probabl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Stemming\n",
    "[port.stem(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scifi',\n",
       " 'fantasy',\n",
       " 'anime',\n",
       " 'styled',\n",
       " 'series',\n",
       " 'guy',\n",
       " 'trying',\n",
       " 'save',\n",
       " 'world',\n",
       " 'probably']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lemmatizing\n",
    "[wnl.lemmatize(w) for w in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_processing(text, method=None):\n",
    "    # Lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove non-letters &\n",
    "    # Tokenize    \n",
    "    words = nltk.wordpunct_tokenize(re.sub('[^a-zA-Z_ ]', '', text))\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Stemming vs Lemmatizing vs do nothing\n",
    "    if method == \"stem\":\n",
    "        port = PorterStemmer()\n",
    "        words = [port.stem(w) for w in words]\n",
    "    elif method == \"lemm\":\n",
    "        wnl = WordNetLemmatizer()\n",
    "        words = [wnl.lemmatize(w) for w in words]\n",
    "\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>stemming</th>\n",
       "      <th>lemmatizing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scifi</td>\n",
       "      <td>scifi</td>\n",
       "      <td>scifi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fantasy</td>\n",
       "      <td>fantasi</td>\n",
       "      <td>fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anime</td>\n",
       "      <td>anim</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>styled</td>\n",
       "      <td>style</td>\n",
       "      <td>styled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>seri</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>guys</td>\n",
       "      <td>guy</td>\n",
       "      <td>guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trying</td>\n",
       "      <td>tri</td>\n",
       "      <td>trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>save</td>\n",
       "      <td>save</td>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>probably</td>\n",
       "      <td>probabl</td>\n",
       "      <td>probably</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw stemming lemmatizing\n",
       "0     scifi    scifi       scifi\n",
       "1   fantasy  fantasi     fantasy\n",
       "2     anime     anim       anime\n",
       "3    styled    style      styled\n",
       "4    series     seri      series\n",
       "5      guys      guy         guy\n",
       "6    trying      tri      trying\n",
       "7      save     save        save\n",
       "8     world    world       world\n",
       "9  probably  probabl    probably"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df[\"document\"][1]\n",
    "\n",
    "compare = {\n",
    "    \"raw\" : text_processing(text),\n",
    "    \"stemming\": text_processing(text, method=\"stem\"),\n",
    "    \"lemmatizing\": text_processing(text, method=\"lemm\")    \n",
    "}\n",
    "pd.DataFrame.from_dict(compare)[[\"raw\", \"stemming\", \"lemmatizing\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find some words are untouched:\n",
    "    - scifi\n",
    "    - save\n",
    "    - world\n",
    "- Some words are touched only in stemming:\n",
    "    - fantsy-fantasi\n",
    "    - anime->anim\n",
    "    - styled->style\n",
    "    - series->seri\n",
    "    - trying->tri    \n",
    "    - probably->probabl\n",
    "- Agreement of stemming and lemmatizng\n",
    "    - guys->guy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "(Aside) How does stemming compare for other words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tri', 'triangl', 'tripl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[port.stem(w) for w in [\"trying\", \"triangle\", \"triple\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seri', 'seriou']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[port.stem(w) for w in [\"series\", \"serious\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
